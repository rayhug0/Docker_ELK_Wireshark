{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> MALWARE TRAFFIC ANALYSIS WITH ELK STACK </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"300\" height=\"200\" src=\"./pic/Telecom.jpg\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <center> Project : Manipulating ELK Stack </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <strong> Formation : </strong> Mastère Spécialisé Big Data : gestion et analyse de données massives </center> \n",
    "<center> <strong> Auteur : </strong> Maxime Geay  </center> \n",
    "<center> <strong> Année : </strong> 2020-2021  </center>   \n",
    "<center> <strong> Encadrant : </strong> Julien Dreano </center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sommaire <a class=\"anchor\" id=\"sommaire\"></a>\n",
    "\n",
    "* [Contexte et rappel des objectifs ](#sect1)\n",
    "* [Data](#sect2)\n",
    "* [Framework](#sect3)\n",
    "* [Installation](#sect4)\n",
    "* [Architecture](#sect5)\n",
    "* [Indexation des données](#sect6)\n",
    "* [Indexation des données](#sect7)\n",
    "* [Dashboard Kibana](#sect8)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexte et rappel des objectifs <a class=\"anchor\" id=\"sect1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet est proposé dans le cadre du cours Cybersécurité du Mastère Spécialisé Big Data dispensé à Télécom Paris.\n",
    "\n",
    "L'objectif étant de construire la stack ELK et de la manipuler a des fin d'analyse de la donnée. Cette donnée est en fait des fichiers pcap.\n",
    "\n",
    "Un fichier pcap (« packet capture ») est une interface de programmation permettant de capturer un trafic réseau.\n",
    "Il s'agit plus particulièrement d'un type de fichier généré lors de la capture du trafic réseau contenant des informations sur des paquets de réseau. (Wireshark est un logiciel permettant une telle capture.)\n",
    "\n",
    "Etapes du projet :\n",
    "\n",
    "   - Construire le framework (Docker)\n",
    "   - Collecter les données (Wireshark + Logstash)\n",
    "   - Indexation des données (Logstash)\n",
    "   - Dashboard (Kibana)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data <a class=\"anchor\" id=\"sect2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce projet, on se servira de l'application Netresec NetworkMiner (https://www.netresec.com/?page=pcapfiles) qui est une application classée comme un programme d'analyse légale de réseau.\n",
    "\n",
    "NetworkMiner permet aux utilisateurs de déterminer des informations relatives au réseau comme les `types de système` et `les versions des ordinateurs` qui sont connectés au réseau ou qui essaient d'accéder aux ressources du réseau, ainsi que les `adresses IP` de ces machines, les `ports ouverts`, les `noms d'hôtes` et `les journaux de session active` entre autres. \n",
    "\n",
    "**Point de vue métier** :\n",
    "\n",
    "D'autres fonctionnalités de capture de paquets et de reniflage passif sont également intégrées dans NetworkMiner de Netresec. Elles peuvent être utilisées par les administrateurs système et le personnel informatique pour sécuriser le réseau et optimiser l'efficacité des ressources liées à la protection et à la confidentialité qui sont disponibles pour tous les ordinateurs et appareils auxquels l'accès au réseau a été accordé.\n",
    "\n",
    "**NB:** NetworkMiner de Netresec a été conçu pour recueillir des détails criminalistiques sur le réseau et non des données sur le trafic réseau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser les données téléchargeables ici : https://www.malware-traffic-analysis.net/2020/12/31/index.html il s'agit de donnée d'analyse du trafic des malwares par des logiciels malveillants sous Windows. (size : environ 20MB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Framework <a class=\"anchor\" id=\"sect3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La suite ELK est disponible gratuitement sur le web. Il s'agit de 3 projets open source : **E**lasticSearch pour la recherche et l'analyse de la donnée, **L**ogstash pour le traitement de la donnée coté serveur et **K**ibana coté client pour visualiser la donnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/framework.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ELK veut faciliter et accélérer la recherche et l’analyse de grands ensembles de données.\n",
    "\n",
    "   - Elasticsearch va permettre d’extraire les données, Logstash normalise toutes sortes de données temporelles\n",
    "et Kibana apporte un insight.\n",
    "\n",
    "Bien qu’Elasticsearch, Logstash et Kibana aient été conçus pour fonctionner ensemble, chacun d’entre eux\n",
    "est un outil distinct.\n",
    "\n",
    "   - ElasticSearch est un moteur de recherche et d’analyse qui utilise le format JSON. Son objectif est d’extraire\n",
    "efficacement les données à partir de sources de données structurées ou non structurées en temps réel.\n",
    "Elasticsearch utilise Lucene pour fournir les capacités de recherche en texte intégral les plus puissantes\n",
    "disponibles dans n'importe quel produit open-source.\n",
    "\n",
    "   - Logstash est un outil pour la saisie, le traitement et la sortie des données logs. Sa fonction est d’analyser,\n",
    "filtrer et découper les logs pour les transformer en documents formatés à destination d’Elasticsearch.\n",
    "Kibana est un tableau de bord interactif et paramétrable qui permet de visualiser les données stockées dans\n",
    "ElasticSearch. \n",
    "\n",
    "   - Kibana apporte un insight sur les tendances et les modèles sous toutes formes de\n",
    "diagrammes et courbes. Ce dashboard peut être partagé et associé à des visualisations de données pour une\n",
    "communication rapide et intelligente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'utiliser ces trois couches, Docker est un candidat idéal puisqu'il s'agit d'un conteneur qui contient déja la stack ELK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'est-ce que Docker ?**\n",
    "\n",
    "Docker permet d'embarquer une application (fichiers source,environnement d'exécution, librairies, outils et fichiers) dans un ou plusieurs containers logiciels qui pourra s'exécuter sur n'importe quel serveur machine, qu'il soit physique ou virtuel. Docker fonctionne sous Linux comme Windows Server. C'est une technologie qui a pour but de faciliter les déploiements d'application, et la gestion du dimensionnement de l'infrastructure sous-jacente. Elle est proposée par la société Docker, en partie en open source (sous licence Apache 2.0).\n",
    "\n",
    "**Quels sont les avantages de Docker ?**\n",
    "\n",
    "J'ai décidé d'utiliser Docker car à la différence d'une VM, il est plus léger et il se lance rapidement : \n",
    "\n",
    "Contrairement à la virtualisation de serveurs et à une machine virtuelle, le conteneur n’intègre pas de\n",
    "noyau, il s’appuie directement sur le noyau de l'ordinateur sur lequel il est déployé."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/Devenvpopular.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Source** : https://www.journaldunet.fr/web-tech/guide-de-l-entreprise-digitale/1146290-docker-definition-docker-compose-docker-hub-docker-swarm-160919/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation <a class=\"anchor\" id=\"sect4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aisé d'installer docker gratuitement sur le site officiel : https://docs.docker.com/get-docker/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/Docker_install.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "J'utilise personnellement Mac OS, ce qui induit que j'ai directement Docker Compose avec Docker Engine, cependant si vous ne possédez pas de Mac il vous faudra télécharger Docker Compose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'est ce que Docker Compose ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/Docker-compose.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Compose est un outil qui permet de décrire (dans un fichier YAML) et gérer (en ligne de commande) plusieurs conteneurs comme un ensemble de services inter-connectés. Si je travaille sur une application ELK + Wireshark, je vais ici décrire un ensemble composé de 4 conteneurs :\n",
    "\n",
    "- ElasticSearch\n",
    "- Logstash\n",
    "- Kibana\n",
    "- Tshark\n",
    "\n",
    "On peut donc à l'aide d'une seule commande `Docker-compose up` lancer les 4 conteneurs ensemble. \n",
    "\n",
    "Un avantage certain est celui du travail collaboratif puisqu'ici il n'y a pas besoin d'instructions très détaillées afin de lancer les applications. Cela se fait de manière automatique\n",
    "\n",
    "Dans chaque conteneurs se trouve un fichier docker-compose.yml, qui décrit un ensemble de paramètres qui correspondent aux options disponibles lors d’un docker run : l’image à utiliser, les volumes à monter, les ports à ouvrir, etc. Mais on peut également y décrire des éléments supplémentaires, comme la possibilité de « construire » (docker build) une image à la volée avant d’en lancer le conteneur.\n",
    "\n",
    "\n",
    "Le dossier Logstash possède également un fichier conf contenant la pipeline sur le traitement des données : input, filtres, cleaning et output vers Elasticsearch. \n",
    "\n",
    "Le dossier Wireshark contient lui un script bash supplémentaire permettant de convertir les fichiers pcap en fichiers json à l'aide de l'utilitaire TShark.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qu'est ce que Wireshark ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wireshark est une application qui intègre des fonctionnalités permettant de surveiller l'activité pertinente du réseau et de stocker ces éléments de données dans des journaux et des bases de données en vue d'une analyse ultérieure.  \n",
    "\n",
    "Différents protocoles de réseau peuvent être surveillés, suivis et analysés par Wireshark, ce qui fournit aux administrateurs de systèmes de réseau et au personnel informatique un moyen rapide et facile d'améliorer l'efficacité des ports de réseau et des transmissions de données vers et depuis les ordinateurs de réseau, les autres dispositifs connectés au réseau et les serveurs Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois installé on peut cloner un github qui contient les images ELK Docker, prenons par exemple ce github :https://github.com/deviantony/docker-elk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois cloné il suffit de suivre les étapes de set up uniquement car nous n'utiliserons pas des fichiers de log comme présenté dans ce github mais des fichiers pcap comme mentionné précédemment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ensuite ajouter le conteneur wireshark en se plaçant dans le dossier nouvellement crée dans le repertoire cloné via la commande suivante : `docker pull nomdeimage` \n",
    "\n",
    "Vous trouverez via ce lien l'image wireshark que vous souhaitez : https://hub.docker.com/search?q=wireshark&type=image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois fait, il suffit de lancer avec la commande `docker-compose up` la stack. Vous devriez voir apparaître dans docker les images :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/stack_docker.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois la stack lancée il suffit d'attendre quelques secondes pour voir apparaître les informations sur le cluster Elastic http://localhost:9200 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/cluster_Elastic.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "puis après quelques minutes (le temps que wireshark récupère les données, que logstash les traites et les transfère à Elasticsearch) on devrait pouvoir accèder à l'interface de Kibana http://localhost:5601/app/home : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/kibana_home.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour stopper l'environnement il suffit de lancer la commande bash : `docker-compose down -v`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "passons maintenant à l'architecture :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Architecture <a class=\"anchor\" id=\"sect5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On récupère les données sur le site Netressec et on les place en local dans le dossier data qui convient, puis wireshark se charge de convertir les données pcap en json pour les transmettre à logstash qui via sa pipeline de traitement des données (cf fichier `logstash.conf` qui notamment parse convenablement les données en octroyant le bon timestamp c'est à dire celui d'origine et non celui du traitement par wireshark) va finalement envoyer les données à Elasticsearch. Elles seront visible dans kibana après avoir crée un index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/workflow.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexation des données <a class=\"anchor\" id=\"sect6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'onglet discover de Kibana vous pouvez créer un index si les données ont bien été transmises à Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/index_kibana_2.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/index_kibana_3.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Kibana <a class=\"anchor\" id=\"sect7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'onglet Dashboard, il est possible de créer des graphs et tableaux et d'en faire un dashboard, voici un exemple de Dashboard sur les données de Malware.\n",
    "\n",
    "**NB :** Pensez à bien parametrer le time range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img width=\"1000\" height=\"1000\" src=\"./pic/dashboard.png\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Références :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Théorie :\n",
    "\n",
    "https://www.elastic.co/fr/what-is/elk-stack\n",
    "\n",
    "https://docs.docker.com/compose/\n",
    "\n",
    "https://web.leikir.io/docker-compose-un-outil-desormais-indispensable/\n",
    "\n",
    "https://www.reviversoft.com/fr/file-extensions/pcap\n",
    "\n",
    "Pratique : \n",
    "\n",
    "https://github.com/deviantony/docker-elk\n",
    "\n",
    "https://www.elastic.co/fr/blog/analyzing-network-packets-with-wireshark-elasticsearch-and-kibana\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Sommaire](#sommaire)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
